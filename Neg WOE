import pandas as pd
import numpy as np
filtered_df = df[(df["count_exp"] > 0) & (df["count_tu"] > 0)]
# Example DataFrame
data = pd.DataFrame({
    'Feature': ['A', 'B', 'C'],
    'Label_0_Count': [50, 30, 20],  # Good counts (label 0)
    'Label_1_Count': [10, 20, 70],  # Bad counts (label 1)
})

grouped = (
    df[df['Match_flag'] == 1]  # Filter for Match_flag == 1
    .groupby(["App_id", "Acc_type"])  # Group by App_id and Acc_type
    .size()  # Count occurrences
    .reset_index(name="Count")  # Reset index and name the count column
)


# Step 1: Calculate total good (label 0) and bad (label 1) counts
total_good = data['Label_0_Count'].sum()
total_bad = data['Label_1_Count'].sum()

# Step 2: Calculate percentage of good and bad for each category
data['pct_good'] = data['Label_0_Count'] / total_good
data['pct_bad'] = data['Label_1_Count'] / total_bad

# Step 3: Calculate WOE (add a small value to avoid division by zero)
data['WOE'] = np.log((data['pct_good'] + 1e-10) / (data['pct_bad'] + 1e-10))

# Display the result
print(data)




Experian: s3://bmf-analytics-dev-eu-west-2-leobrix/DataDictionaries/ExperianDD.xlsm
TU: s3://bmf-analytics-dev-eu-west-2-leobrix/DataDictionaries/TransUnionRetroDD.pdf




 s3://bmf-analytics-dev-eu-west-2-leobrix/data/Retros/September2024Retros/Experian/RawData/ExperianTradelineData_1k.csv
s3://bmf-analytics-dev-eu-west-2-leobrix/data/Retros/September2024Retros/TransUnion/RawData/TUTradelineData_1k.csv




•	Experian: s3://bmf-analytics-dev-eu-west-2-leobrix/data/Retros/September2024Retros/Experian/RawData/ExperianTradelineData.csv
•	TransUnion: s3://bmf-analytics-dev-eu-west-2-leobrix/data/Retros/September2024Retros/TransUnion/RawData/TUTradelineData.csv
