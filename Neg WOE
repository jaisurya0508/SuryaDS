import pandas as pd
import numpy as np

# Step 1: Filter where MATCH_FLAG == 1
filtered_df = df[df['MATCH_FLAG'] == 1]

# Step 2: Filter further where ACC_TYPE is in ['BA', 'ba'] and count unique IDs
result = (
    filtered_df[filtered_df['ACC_TYPE'].isin(['BA', 'ba'])]  # Filter for ACC_TYPE
    .groupby('ACC_TYPE')['UNIQUEID'].nunique()  # Count unique UNIQUEID values
    .reset_index(name='Unique_ID_Count')  # Reset index for a clean output
)
LoanCredit = [01, 02, 07, 17, 19, 22, 23, 26, 28, 29, 60, 61, 62, 63, 64]
Miscellaneous = [20, 27, 36, 38, 52]
Mortgage = [03, 16, 25, 30, 31, 32, 33, 34, 35, 69]
RevolvingCredit = [04, 05, 06, 37, 44]
Telecomms = [18, 53, 54, 55, 56, 57, 58, 59]
Unknown = [999]
Utilities = [21, 39, 40, 41, 42, 43]





grouped = (
    df[df['Match_flag'] == 1]  # Filter for Match_flag == 1
    .groupby(["App_id", "Acc_type"])  # Group by App_id and Acc_type
    .size()  # Count occurrences
    .reset_index(name="Count")
AccountType	TU
Bank	['BK', 'CA', 'DC', 'DF', 'OD', 'RQ']
HomeShopping	['BC', 'HA', 'HD', 'HS', 'HX', 'MA', 'MO', 'TV', 'WI']
Insurance	['BI', 'CI', 'GI', 'HI', 'IN', 'MI', 'MP', 'PI', 'PP', 'PT']
LoanCredit	['BA', 'BH', 'BL', 'BN', 'BR', 'CP', 'CR', 'CS', 'CX', 'CY', 'DA', 'DH', 'ED', 'EL', 'FD', 'FL', 'FS', 'HP', 'IL', 'LN', 'LP', 'LS', 'ML', 'OL', 'OR', 'PL', 'PR', 'RG', 'RT', 'SB', 'SC', 'SE', 'SL', 'SO', 'TL', 'UL', 'ZH', 'ZL']
Miscellaneous	['AD', 'AF', 'BX', 'CD', 'CT', 'CZ', 'DP', 'EC', 'FT', 'GA', 'GL', 'IC', 'IS', 'LR', 'MC', 'OA', 'RC', 'SA', 'SS', 'TR', 'VS', 'ZC']
Mortgage	['BM', 'CM', 'DM', 'FM', 'FO', 'IM', 'MG', 'MM', 'MT', 'NM', 'OM', 'RM', 'SM', 'SX', 'XM', 'ZM']
RevolvingCredit	['BD', 'CC', 'CH', 'CO', 'FC', 'RS', 'ST']
Telecomms	['AM', 'AU', 'BO', 'BU', 'CB', 'LT', 'MU', 'QA', 'SI', 'TM']
Utilities	['DU', 'EE', 'EW', 'GE', 'OI', 'QE', 'QG', 'QU', 'QW', 'UE', 'UT']
 # Reset index and name the count column
)


# Step 1: Calculate total good (label 0) and bad (label 1) counts
total_good = data['Label_0_Count'].sum()
total_bad = data['Label_1_Count'].sum()

# Step 2: Calculate percentage of good and bad for each category
data['pct_good'] = data['Label_0_Count'] / total_good
data['pct_bad'] = data['Label_1_Count'] / total_bad

# Step 3: Calculate WOE (add a small value to avoid division by zero)
data['WOE'] = np.log((data['pct_good'] + 1e-10) / (data['pct_bad'] + 1e-10))

# Display the result
print(data)




Experian: s3://bmf-analytics-dev-eu-west-2-leobrix/DataDictionaries/ExperianDD.xlsm
TU: s3://bmf-analytics-dev-eu-west-2-leobrix/DataDictionaries/TransUnionRetroDD.pdf




 s3://bmf-analytics-dev-eu-west-2-leobrix/data/Retros/September2024Retros/Experian/RawData/ExperianTradelineData_1k.csv
s3://bmf-analytics-dev-eu-west-2-leobrix/data/Retros/September2024Retros/TransUnion/RawData/TUTradelineData_1k.csv




•	Experian: s3://bmf-analytics-dev-eu-west-2-leobrix/data/Retros/September2024Retros/Experian/RawData/ExperianTradelineData.csv
•	TransUnion: s3://bmf-analytics-dev-eu-west-2-leobrix/data/Retros/September2024Retros/TransUnion/RawData/TUTradelineData.csv
