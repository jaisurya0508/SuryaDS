import pandas as pd
import numpy as np

# Filter where Match_flag == 1 and Acc_type is in ['BA', 'BN']
filtered_df = df[(df['Match_flag'] == 1) & (df['Acc_type'].isin(['BA', 'BN']))]

# Group by App_id and count occurrences
result = (
    filtered_df.groupby('App_id')
    .size()
    .reset_index(name='Count_BA_BN')
)




grouped = (
    df[df['Match_flag'] == 1]  # Filter for Match_flag == 1
    .groupby(["App_id", "Acc_type"])  # Group by App_id and Acc_type
    .size()  # Count occurrences
    .reset_index(name="Count")  # Reset index and name the count column
)


# Step 1: Calculate total good (label 0) and bad (label 1) counts
total_good = data['Label_0_Count'].sum()
total_bad = data['Label_1_Count'].sum()

# Step 2: Calculate percentage of good and bad for each category
data['pct_good'] = data['Label_0_Count'] / total_good
data['pct_bad'] = data['Label_1_Count'] / total_bad

# Step 3: Calculate WOE (add a small value to avoid division by zero)
data['WOE'] = np.log((data['pct_good'] + 1e-10) / (data['pct_bad'] + 1e-10))

# Display the result
print(data)




Experian: s3://bmf-analytics-dev-eu-west-2-leobrix/DataDictionaries/ExperianDD.xlsm
TU: s3://bmf-analytics-dev-eu-west-2-leobrix/DataDictionaries/TransUnionRetroDD.pdf




 s3://bmf-analytics-dev-eu-west-2-leobrix/data/Retros/September2024Retros/Experian/RawData/ExperianTradelineData_1k.csv
s3://bmf-analytics-dev-eu-west-2-leobrix/data/Retros/September2024Retros/TransUnion/RawData/TUTradelineData_1k.csv




•	Experian: s3://bmf-analytics-dev-eu-west-2-leobrix/data/Retros/September2024Retros/Experian/RawData/ExperianTradelineData.csv
•	TransUnion: s3://bmf-analytics-dev-eu-west-2-leobrix/data/Retros/September2024Retros/TransUnion/RawData/TUTradelineData.csv
