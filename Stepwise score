from sklearn.metrics import roc_auc_score
from sklearn.linear_model import LogisticRegression
import pandas as pd
from joblib import Parallel, delayed

def forward_selection(x_train, y_train, threshold_in=0.01, n_jobs=-1):
    """
    Perform forward selection using Logistic Regression with AUC as the metric.
    Optimized for large datasets with AUC and Gini tracking.
    """
    initial_features = list(x_train.columns)
    selected_features = []
    best_score = 0  # Start with a baseline AUC score
    results = []  # To store feature selection results

    print(f"Starting Forward Selection with {len(initial_features)} features...")
    
    while initial_features:
        scores_with_candidates = []

        # Parallelized feature evaluation
        def evaluate_feature(feature):
            current_features = selected_features + [feature]
            model = LogisticRegression(max_iter=500, solver='liblinear', random_state=42)
            try:
                model.fit(x_train[current_features], y_train)
                y_pred = model.predict_proba(x_train[current_features])[:, 1]
                auc = roc_auc_score(y_train, y_pred)
                return (feature, auc)
            except Exception as e:
                print(f"Error with feature {feature}: {e}")
                return (feature, None)
        
        scores_with_candidates = Parallel(n_jobs=n_jobs)(
            delayed(evaluate_feature)(feature) for feature in initial_features
        )
        
        # Filter out features that failed (returned None)
        scores_with_candidates = [score for score in scores_with_candidates if score[1] is not None]

        # If no candidates improve the score, break the loop
        if not scores_with_candidates:
            print("No more features to evaluate. Stopping.")
            break
        
        # Find the best feature and its corresponding score
        best_new_feature, best_new_score = max(scores_with_candidates, key=lambda x: x[1])
        
        # Add feature if it improves AUC beyond the threshold
        if best_new_score - best_score > threshold_in:
            selected_features.append(best_new_feature)
            initial_features.remove(best_new_feature)
            best_score = best_new_score
            gini = 2 * best_new_score - 1
            results.append({
                "Feature": best_new_feature,
                "AUC": best_new_score,
                "Gini": gini
            })
            print(f"Selected Feature: {best_new_feature} | AUC: {best_new_score:.4f} | Gini: {gini:.4f}")
        else:
            print("No significant improvement. Stopping.")
            break

    print(f"Forward Selection completed. Selected {len(selected_features)} features.")
    return pd.DataFrame(results)

# Example usage
# Assuming X_train and y_train are your feature matrix and target variable
# results_df = forward_selection(X_train, y_train, threshold_in=0.01)
# results_df.to_csv("forward_selection_results.csv", index=False)
